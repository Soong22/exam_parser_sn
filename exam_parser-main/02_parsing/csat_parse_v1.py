from __future__ import annotations

import json, re, os, unicodedata, glob, sys
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from table_utils import sanitize_table_html
from image_utils import ImageConfig, classify_and_store_image

# =============================================================================
# 1) ìƒìˆ˜Â·ì •ê·œì‹
# =============================================================================

_DOT_DATE_TAIL_GUARD = (
    r"(?!"
    r"\s*\d{1,2}\s*[.ã€‚ï¼]\s*"
    r"(?:\d{2,4}\s*[.ã€‚ï¼]\s*)?"
    r"(?:$|[^\wê°€-í£]|[ë…„ì›”ì¼])"
    r")"
)

# ì„ íƒì§€ ë™ê·¸ë¼ë¯¸ ë§ˆì»¤(ìœ ë‹ˆì½”ë“œ)
RE_CIRCLED_NUM = r"[\u2460-\u2473\u24ea\u24f5-\u24fe]"
RE_MARKER_TOKEN = re.compile(r"\(?\s*(" + RE_CIRCLED_NUM + r")\s*\)?")

# ë¬¸ì œë²ˆí˜¸ íŒ¨í„´ (ì›í˜•ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì€ ì œì™¸)
RE_Q_HEADER = re.compile(
    rf"^(?!\s*{RE_CIRCLED_NUM})\s*(?:ë¬¸\s*)?([1-9]\d{{0,2}})\s*(?:\)|[.ã€‚ï¼])\s+{_DOT_DATE_TAIL_GUARD}",
    re.UNICODE,
)

RE_LEAD_QNUM = re.compile(
    rf"^\s*(?:ë¬¸\s*)?\d{{1,3}}\s*(?:\)\s+|[.ã€‚ï¼]\s+{_DOT_DATE_TAIL_GUARD})",
    re.UNICODE,
)

# '<ë³´ê¸°>' ì¸ì‹
RE_BOGI_TAG_LINE = re.compile(r"(?m)^[ \t]*[<\[]?\s*ë³´\s*ê¸°\s*[>\]]?")
RE_BOGI_TAG_AT_START = re.compile(r"^[ \t]*[<\[]?\s*ë³´\s*ê¸°\s*[>\]]?\s*")
RE_BOGI_TAG = re.compile(r"[<\[]?\s*ë³´\s*ê¸°\s*[>\]]?", re.UNICODE)

# í”Œë ˆì´ìŠ¤í™€ë”
_PH_RE = re.compile(r"<<(?:IMG|FORM|TBL)_\d+>>")

# 'ã„±. ã„´. ã„·. â€¦' ì—´ê±°
RE_VIEW_ENUM_START = re.compile(r"(?:^|\n|\s)(?:ã„±|ã„´|ã„·|ã„¹|ã…|ã…‚|ã……|ã…‡|ã…ˆ|ã…Š|ã…‹|ã…Œ|ã…|ã…)\s*[)\.]\s*")

# ê°™ì€ ë¸”ë¡ì— ì„ íƒì§€ê°€ ë¶™ì€ ê²½ìš°(â‘ ~â‘³)
RE_CHOICE_INLINE = re.compile(r"[\u2460-\u2473]")

# ì¸ë¼ì¸ LaTeX (\(...\))
RE_INLINE_TEX = re.compile(r"(\\\(.+?\\\))", re.S)

# HTML <table>
RE_HTML_TABLE = re.compile(r"<\s*table\b.*?</\s*table\s*>", re.I | re.S)

# Zero width
RE_ZERO_WIDTH = re.compile("[\u200B\u200C\u200D\u200E\u200F\u2060\u2066\u2067\u2068\u2069\ufeff\u00ad\u2028\u2029]")

# ë³´ê¸° ë¼ë²¨(ã‰ -ã‰¯ ë˜ëŠ” ã„±-ã…)
RE_VIEW_UNIT = re.compile(r"(?<!\S)([ã‰ -ã‰¯]|[ã„±-ã…])\s*[)\.]?\s*")

# Circled number â†’ plain number ë§¤í•‘ (ì •ë ¬/íŒë‹¨ìš©ë§Œ ì‚¬ìš©, ì €ì¥ì€ ì›í˜•ìˆ«ì ìœ ì§€)
UC2NUM = {chr(0x2460 + i): str(i + 1) for i in range(20)}
UC2NUM.update({"\u24ea": "0"})  # â“ª
UC2NUM.update({chr(0x24F5 + i): str(i + 1) for i in range(10)})

# âœ… ìˆ«ì â†’ ê¸°ë³¸ ì›í˜•ìˆ«ì(â‘ ..â‘³, â“ª) (fallbackìš©)
NUM2UC = {"0": "\u24ea", **{str(i): chr(0x2460 + (i - 1)) for i in range(1, 21)}}  # 1â†’â‘ , 2â†’â‘¡, ...

# ì´ë¯¸ì§€/ê²½ë¡œ ê¸°ë³¸ ì„¤ì •
IMAGES_SRC_DIR = r"images"
IMAGES_IMG_DIR = os.path.join(IMAGES_SRC_DIR, "image")
IMAGES_TBL_DIR = os.path.join(IMAGES_SRC_DIR, "table")
IMAGES_FORM_DIR = os.path.join(IMAGES_SRC_DIR, "formula")  # âœ… ìˆ˜ì‹ ì „ìš© í´ë” ì¶”ê°€
IMAGES_INDEX_DIR = os.path.join(IMAGES_SRC_DIR, "_index")
IMAGE_MOVE = False
IMAGE_OVERWRITE = True

# ì…ì¶œë ¥ ê¸°ë³¸ í´ë”
LAYOUT_DIR = r"exam_parser-main\01_middle_process\data\merge_html"        # ì…ë ¥: *.json
FORMAT_DIR = r"exam_parser-main\02_parsing\data\00_final"               # ì¶œë ¥: *.jsonl
ANSWER_DIR = r"exam_parser-main\02_parsing\data\ì •ë‹µ\2025_ì§ì—…íƒêµ¬ì˜ì—­_ì •ë‹µ_ê°œì„ ë³¸"                              # ë¹„ì›Œë‘ë©´ ìë™ íƒìƒ‰

# =============================================================================
# 2) ê²½ë¡œ/ê¸€ë¡œë²Œ ìœ í‹¸ (ë§¥/ìœˆë„ìš° ê³µí†µ ì•ˆì „í™”)
# =============================================================================

def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)

def _normalize_compat_jamo(s: str) -> str:
    if not s:
        return s
    s2 = unicodedata.normalize("NFKC", s)
    JAMO_CHO_SRC = "á„€á„á„‚á„ƒá„„á„…á„†á„‡á„ˆá„‰á„Šá„‹á„Œá„á„á„á„á„‘á„’"
    JAMO_CHO_DST = "ã„±ã„²ã„´ã„·ã„¸ã„¹ã…ã…‚ã…ƒã……ã…†ã…‡ã…ˆã…‰ã…Šã…‹ã…Œã…ã…"
    trans = str.maketrans({s: d for s, d in zip(JAMO_CHO_SRC, JAMO_CHO_DST)})
    return s2.translate(trans)

def normalize_text(s: str) -> str:
    if not s:
        return ""
    s = _normalize_compat_jamo(s)
    s = RE_ZERO_WIDTH.sub("", s)
    return s

def strip_leading_qnum(s: str) -> str:
    return RE_LEAD_QNUM.sub("", s, count=1)

def clean_text(s: str) -> str:
    if not s:
        return ""
    s = normalize_text(s).replace("\u00A0", " ").replace("$", "")
    s = re.sub(r"\s+", " ", s)
    return s.strip()

def clean_text_keep_newlines(s: str) -> str:
    if not s:
        return ""
    s = normalize_text(s).replace("\u00A0", " ").replace("$", "")
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"[ \t\r]*\n[ \t\r]*", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()

def _abs_norm(p: str) -> str:
    """~ / í™˜ê²½ë³€ìˆ˜ / ì ˆëŒ€ê²½ë¡œ / NFC í†µí•©"""
    p2 = os.path.abspath(os.path.expanduser(os.path.expandvars(p or "")))
    return unicodedata.normalize("NFC", p2)

def _to_nfd(p: str) -> str:
    return unicodedata.normalize("NFD", p or "")

def safe_glob(dir_path: str, pattern: str, recursive: bool = True) -> List[str]:
    """ë§¥(NFD)Â·ìœˆë„ìš°(NFC) ëª¨ë‘ì—ì„œ í•œ ë²ˆì— ì¡íˆë„ë¡ ê¸€ë¡­ ì´ì¤‘ ì‹œë„"""
    out: List[str] = []
    if not dir_path:
        return out
    d_nfc = _abs_norm(dir_path)
    d_nfd = _to_nfd(d_nfc) if sys.platform == "darwin" else d_nfc

    pats = [pattern]
    # ê²¬ê³ ì„±: *-ì •ë‹µ.jsonl ì™¸ì—ë„ *ì •ë‹µ*.jsonl í—ˆìš©
    if pattern == "*-ì •ë‹µ.jsonl":
        pats.append("*ì •ë‹µ*.jsonl")

    for root in {d_nfc, d_nfd}:
        for pat in pats:
            glob_pat = os.path.join(root, "**", pat) if recursive else os.path.join(root, pat)
            out.extend(glob.glob(glob_pat, recursive=recursive))
    # ì¤‘ë³µ ì œê±° + ì •ë ¬
    uniq = sorted({_abs_norm(p) for p in out})
    return uniq

# =============================================================================
# 3) ìˆ˜ì‹/ì´ë¯¸ì§€/í…Œì´ë¸” í”Œë ˆì´ìŠ¤í™€ë”
# =============================================================================

def _strip_math_delims(s: str) -> str:
    s = s.strip()
    if s.startswith(r"\(") and s.endswith(r"\)"):
        return s[2:-2].strip()
    return s

FORMULA_BLOCK_TYPES = {"formula", "inline_equation"}

def _latex_from_block(b: Dict[str, Any]) -> str:
    return str(b.get("content") or b.get("latex") or b.get("text") or "")

def insert_formula_placeholders(text: str, cur: Dict[str, Any]) -> str:
    if not text:
        return text
    def repl(m: re.Match) -> str:
        latex_raw = m.group(1)
        forms = cur.setdefault("_forms", [])
        idx = len(forms)
        forms.append({"latex": latex_raw})
        return f"<<FORM_{idx}>>"
    return RE_INLINE_TEX.sub(repl, text)

def insert_table_placeholders(text: str, cur: Dict[str, Any]) -> str:
    if not text:
        return text
    out = []
    pos = 0
    while True:
        m = RE_HTML_TABLE.search(text, pos)
        if not m:
            out.append(text[pos:]); break
        out.append(text[pos:m.start()])
        html_src = m.group(0)
        tables = cur.setdefault("_tables", [])
        idx = len(tables)
        tables.append({"html": sanitize_table_html(html_src), "file_name": "", "bbox": [], "page_idx": None, "title": ""})
        out.append(f"<<TBL_{idx}>>")
        pos = m.end()
    return "".join(out)

# =============================================================================
# 4) ì´ë¯¸ì§€ ìº¡ì…˜ ì¶”ì •/ì„ íƒì§€ ë„ìš°ë¯¸
# =============================================================================

def _bbox_overlaps_horiz(b1: List[int], b2: List[int]) -> bool:
    x11, _, x12, _ = b1
    x21, _, x22, _ = b2
    return max(0, min(x12, x22) - max(x11, x21)) > 0

def _guess_image_title(blocks: List[Dict[str, Any]], idx: int) -> str:
    b = blocks[idx]
    page = b.get("page_idx")
    bbox = b.get("bbox") or [0, 0, 0, 0]
    x1, y1, x2, y2 = bbox if len(bbox) == 4 else (0, 0, 0, 0)
    # âœ… caption í‚¤ê¹Œì§€ í¬í•¨í•´ì„œ íƒìƒ‰
    caps = (b.get("image_caption") or []) + (b.get("image_footnote") or [])
    cap = b.get("caption")
    if cap:
        if isinstance(cap, str):
            caps.append(cap)
        else:
            try:
                caps.extend(list(cap))
            except Exception:
                pass
    for c in caps:
        c = clean_text(c)
        if c: return c
    TH = 60
    for j in range(idx - 1, -1, -1):
        pb = blocks[j]
        if pb.get("type") != "text": continue
        if pb.get("page_idx") != page: break
        bb = pb.get("bbox") or [0, 0, 0, 0]
        _, by1, _, by2 = bb if len(bb) == 4 else (0, 0, 0, 0)
        if by2 <= y1 and (y1 - by2) <= TH and _bbox_overlaps_horiz(bbox, bb):
            txt = clean_text(pb.get("text", ""))
            if re.search(r"(ê·¸ë¦¼|Fig\.?|ë„\s*\d+)", txt, re.I):
                return txt
    return ""

def explode_inline_choice_blocks(blocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    for b in blocks:
        t = b.get("text", "")
        if not isinstance(t, str) or not t.strip():
            out.append(b); continue
        parts = RE_MARKER_TOKEN.split(t)
        if len(parts) >= 5:
            i = 1
            while i < len(parts):
                token = parts[i]; tail = parts[i+1] if i+1 < len(parts) else ""
                i += 2
                nb = dict(b); nb["text"] = (token or "") + (tail or "")
                out.append(nb)
        else:
            out.append(b)
    return out

def _rebalance_choice_assets(pairs: List[Tuple[str, str]]) -> List[Tuple[str, str]]:
    if not pairs: return pairs
    bodies = [b or "" for _, b in pairs]
    tokens = _PH_RE.findall("\n".join(bodies))
    if not tokens: return pairs
    only_assets = [(_PH_RE.sub("", b).strip() == "") for b in bodies]
    if all(only_assets):
        it = iter(tokens)
        new_pairs = []
        for lab, body in pairs:
            tok = next(it, None)
            new_pairs.append((lab, tok if tok is not None else body))
        return new_pairs
    return pairs

_CONNECTOR_ONLY_RE = re.compile(r"^[\s\-\~â€“â€”,Â·.\u00B7ï¼/\\()\[\]{}<>:;|]*$")

def _is_marker_decor_line(s: str) -> bool:
    if not s or not s.strip(): return False
    u = normalize_text(s)
    circ_cnt = len(RE_MARKER_TOKEN.findall(u))
    if circ_cnt < 2: return False
    tmp = RE_MARKER_TOKEN.sub("", u)
    return _CONNECTOR_ONLY_RE.match(tmp.strip() or "") is not None

def _find_tail_start_idx(marks: List[Tuple[int,int,str,Optional[int],str]]) -> Optional[int]:
    """
    marks[i] = (start, end, raw_circled_char, numeric_value_or_None, kind)
    ë’¤ì—ì„œë¶€í„° 'â‘ '(numeric=1)ì„ ì°¾ì•„ ê·¸ ìœ„ì¹˜ë¥¼ ì‹œì‘ì ìœ¼ë¡œ ì‚¬ìš©.
    """
    n = len(marks)
    if n < 2: return None
    for i in range(n - 2, -1, -1):
        if marks[i][3] == 1:
            return i
    return n - 2

def slice_choices_by_markers_tailonly(big_text: str) -> Tuple[List[Tuple[str, str]], str]:
    """
    ë³¸ë¬¸ ë’¤ìª½ì—ì„œ ë¶™ì€ ì„ íƒì§€ë¥¼ tail-only ë°©ì‹ìœ¼ë¡œ ë¶„ë¦¬.
    ë¼ë²¨ì€ ì›í˜•ìˆ«ì ê·¸ëŒ€ë¡œ ì‚¬ìš©.
    """
    if not big_text: return [], ""
    raw_keep = RE_ZERO_WIDTH.sub("", big_text or "")
    marks = _gather_markers_with_kind(raw_keep)  # (s,e,raw,num,kind)
    if len(marks) < 2:
        pref = re.sub(r"[ \t]+\n", "\n", big_text or "")
        pref = re.sub(r"\n{3,}", "\n\n", pref).strip()
        return [], pref
    start_idx = _find_tail_start_idx(marks)
    if start_idx is None:
        pref = re.sub(r"[ \t]+\n", "\n", big_text or "")
        pref = re.sub(r"\n{3,}", "\n\n", pref).strip()
        return [], pref
    prefix = re.sub(r"[ \t]+\n", "\n", raw_keep[:marks[start_idx][0]]).strip()
    out: List[Tuple[str, str]] = []
    n = len(marks)
    for k in range(start_idx, n):
        s_k = marks[k][1]
        e_k = marks[k + 1][0] if (k + 1) < n else len(raw_keep)
        lab = marks[k][2]  # ì›í˜•ìˆ«ì ê·¸ëŒ€ë¡œ
        chunk = (raw_keep[s_k:e_k] or "").strip()
        out.append((lab, chunk))
    out = _rebalance_choice_assets(out)
    return out, prefix

def _peel_decor_edges(s: str) -> Tuple[str, str]:
    if not s: return "", ""
    lines = s.splitlines()
    i, j = 0, len(lines)-1
    head, tail = [], []
    while i <= j and _is_marker_decor_line(lines[i]): head.append(lines[i]); i += 1
    while j >= i and _is_marker_decor_line(lines[j]): tail.append(lines[j]); j -= 1
    decor = "\n".join(head + list(reversed(tail))).strip()
    rest  = "\n".join(lines[i:j+1]).strip()
    decor = re.sub(r"[ \t]+\n", "\n", decor).strip()
    rest  = re.sub(r"[ \t]+\n", "\n", rest).strip()
    return decor, rest

def _gather_markers_with_kind(text: str) -> List[Tuple[int, int, str, Optional[int], str]]:
    """
    RE_MARKER_TOKEN ìœ¼ë¡œ ì°¾ì€ ì›í˜•ìˆ«ì ë§ˆì»¤ë“¤ì„ ìˆ˜ì§‘.
    ë°˜í™˜: (start_idx, end_idx, raw_circled_char, numeric_value(int|None), "circled")
    """
    out: List[Tuple[int, int, str, Optional[int], str]] = []
    raw_keep = text or ""
    for m in RE_MARKER_TOKEN.finditer(raw_keep):
        ch = m.group(1)  # ì›í˜•ìˆ«ì ìì²´
        num = UC2NUM.get(ch)
        num_i = int(num) if num and num.isdigit() else None
        out.append((m.start(), m.end(), ch, num_i, "circled"))
    out.sort(key=lambda x: x[0])
    return out

def slice_choices_by_markers(big_text: str) -> Tuple[List[Tuple[str, str]], str]:
    """
    ë³¸ë¬¸ ë¬¸ìì—´ì—ì„œ ì›í˜•ìˆ«ì ë§ˆì»¤ë“¤ë¡œ ì„ íƒì§€ë¥¼ ë¶„ë¦¬.
    ë¼ë²¨ì€ ì›í˜•ìˆ«ì ê·¸ëŒ€ë¡œ ì‚¬ìš©.
    """
    raw_keep = RE_ZERO_WIDTH.sub("", big_text or "")
    raw_norm = normalize_text(big_text)
    marks: List[Tuple[int, int, str]] = []
    for m in RE_MARKER_TOKEN.finditer(raw_keep):
        ch = m.group(1)  # ì›í˜•ìˆ«ì ê·¸ëŒ€ë¡œ
        marks.append((m.start(), m.end(), ch))
    marks.sort(key=lambda x: x[0])
    if marks:
        prefix = clean_text_keep_newlines(raw_keep[:marks[0][0]])
        out: List[Tuple[str, str]] = []
        for i, (s, e, lab) in enumerate(marks):
            start = e
            end = marks[i+1][0] if i+1 < len(marks) else len(raw_keep)
            chunk = clean_text(raw_keep[start:end])
            if lab: out.append((lab, chunk))
        out = _rebalance_choice_assets(out)
        return out, prefix
    return [], clean_text_keep_newlines(raw_norm)

def _has_view_enumeration_with_content(s: str) -> bool:
    if not s or not s.strip(): return False
    u = normalize_text(s)
    matches = list(RE_VIEW_UNIT.finditer(u))
    if len(matches) < 2: return False
    substantive = 0
    for idx, m in enumerate(matches):
        start = m.end()
        end   = matches[idx+1].start() if idx+1 < len(matches) else len(u)
        chunk = clean_text_keep_newlines(u[start:end]).strip()
        if chunk and not _CONNECTOR_ONLY_RE.match(chunk):
            substantive += 1
    return substantive >= 1

def route_prefix_generically(prefix: str) -> Tuple[str, str]:
    if not prefix or not prefix.strip(): return "", ""
    decor, core = _peel_decor_edges(prefix)
    if not core.strip(): return decor, ""
    m = RE_BOGI_TAG_LINE.search(core)
    if m:
        before = core[:m.start()].rstrip()
        after  = core[m.start():].lstrip()
        to_body = "\n".join(x for x in [decor, re.sub(r"[ \t]+\n", "\n", before).strip()] if x).strip()
        aft = re.sub(r"[ \t]+\n", "\n", after)
        m2 = RE_VIEW_UNIT.search(aft)
        if m2:
            head = aft[:m2.start()].strip()
            packed = _pack_view_with_newlines(aft[m2.start():])
            to_view = (head + ("\n" if head and packed else "") + packed).strip()
        else:
            to_view = aft.strip()
        return to_body, to_view
    if _has_view_enumeration_with_content(core):
        to_view = _pack_view_with_newlines(re.sub(r"[ \t]+\n", "\n", core))
        return decor, to_view
    core2 = re.sub(r"[ \t]+\n", "\n", core).strip()
    to_body = (decor + ("\n" if decor and core2 else "") + core2).strip()
    return to_body, ""

def _pack_view_with_newlines(vtxt: str) -> str:
    s = (vtxt or "").strip()
    if not s: return s
    items = []
    matches = list(RE_VIEW_UNIT.finditer(s))
    if not matches: return s
    for idx, m in enumerate(matches):
        lab = m.group(1)
        content_start = m.end()
        content_end = matches[idx + 1].start() if idx + 1 < len(matches) else len(s)
        chunk = s[content_start:content_end].strip()
        if 'ã„±' <= lab <= 'ã…': items.append(f"{lab}. {chunk}".strip())
        else: items.append(f"{lab} {chunk}".strip())
    out = "\n".join(it for it in items if it)
    out = re.sub(r"\n+", "\n", out).strip()
    return out

# =============================================================================
# 5) Question ëª¨ë¸
# =============================================================================

@dataclass
class Question:
    number: str
    body: str = ""
    view: str = ""
    choices: Dict[str, str] = field(default_factory=dict)
    _images: List[Dict[str, Any]] = field(default_factory=list)
    _forms: List[Dict[str, Any]] = field(default_factory=list)
    _tables: List[Dict[str, Any]] = field(default_factory=list)
    _chunks: List[str] = field(default_factory=list)

# =============================================================================
# 6) ë³¸ë¬¸/ë³´ê¸° ë¶„ë¦¬
# =============================================================================

def _split_question_and_view(text: str) -> Tuple[str, str]:
    if not text: return "", ""
    s = RE_ZERO_WIDTH.sub("", text or "")
    m_bogi = RE_BOGI_TAG_LINE.search(s)
    start_idx = m_bogi.start() if m_bogi else None
    m_bul = RE_VIEW_ENUM_START.search(s)
    if m_bul and (start_idx is None or m_bul.start() < start_idx):
        start_idx = m_bul.start()
    if start_idx is None:
        return s.strip(), ""
    qtxt = s[:start_idx].rstrip()
    vtxt = s[start_idx:].lstrip()
    m_choice = RE_CHOICE_INLINE.search(vtxt)
    if m_choice:
        vtxt = vtxt[: m_choice.start()].rstrip()
    aft = re.sub(r"[ \t]+\n", "\n", vtxt)
    m2 = RE_VIEW_UNIT.search(aft)
    if m2:
        head = aft[:m2.start()].strip()
        packed = _pack_view_with_newlines(aft[m2.start():])
        v_out = (head + ("\n" if head and packed else "") + packed).strip()
    else:
        v_out = aft.strip()
    return qtxt, v_out

# =============================================================================
# 7) ì¶”ì¶œê¸°
# =============================================================================

def extract(doc: Any) -> List[Question]:
    if isinstance(doc, dict):
        blocks = doc.get("items") or doc.get("blocks") or []
        if not blocks and "pages" in doc:
            blocks = [b for p in doc["pages"] for b in p.get("blocks", [])]
    else:
        blocks = doc
    blocks = explode_inline_choice_blocks(blocks)
    res: List[Question] = []
    cur: Optional[Question] = None

    def push():
        nonlocal cur
        if not cur: return
        if not cur.choices: cur.choices = {}
        res.append(cur); cur = None

    i, n = 0, len(blocks)
    while i < n:
        b = blocks[i]
        btype = b.get("type")
        text = (b.get("text") or "") if btype == "text" else ""
        if btype == "text":
            head = normalize_text(text).strip()
            m = RE_Q_HEADER.match(head)
            if m:
                new_num = m.group(1)
                if cur is not None and str(cur.number) == new_num:
                    body0 = strip_leading_qnum(text)
                    body0 = insert_formula_placeholders(body0, cur.__dict__)
                    body0 = insert_table_placeholders(body0, cur.__dict__)
                    qtxt, vtxt = _split_question_and_view(body0)
                    qtxt = (qtxt or "").strip()
                    vtxt = re.sub(r"[ \t]+\n", "\n", vtxt or "")
                    vtxt = re.sub(r"\n{3,}", "\n\n", vtxt).strip()
                    if qtxt: cur.body = (cur.body + ("\n" if cur.body else "") + qtxt).strip()
                    if vtxt: cur.view = (cur.view + ("\n" if cur.view and vtxt else "") + vtxt).strip()
                    i += 1; continue
                push()
                cur = Question(number=new_num)
                body0 = strip_leading_qnum(text)
                body0 = insert_formula_placeholders(body0, cur.__dict__)
                body0 = insert_table_placeholders(body0, cur.__dict__)
                qtxt, vtxt = _split_question_and_view(body0)
                cur.body = (qtxt or "").strip()
                if vtxt:
                    vv = re.sub(r"[ \t]+\n", "\n", vtxt)
                    vv = re.sub(r"\n{3,}", "\n\n", vv).strip()
                    cur.view = vv
                i += 1; continue

        if cur is not None:
            j = i
            big_parts: List[str] = []
            while j < n:
                nb = blocks[j]
                nbtype = nb.get("type")
                if nbtype == "text":
                    t = nb.get("text", "")
                    if RE_Q_HEADER.match(normalize_text(t).strip()): break
                    t = insert_formula_placeholders(t, cur.__dict__)
                    t = insert_table_placeholders(t, cur.__dict__)
                    big_parts.append(t)
                elif nbtype in FORMULA_BLOCK_TYPES:
                    latex_txt = _latex_from_block(nb)
                    idx_for_form = len(cur._forms)
                    cur._forms.append({
                        "latex": latex_txt,
                        "image_path": nb.get("image_path") or nb.get("img_path") or "",
                        "bbox": nb.get("bbox") or [],
                        "page_idx": nb.get("page_idx"),
                    })
                    big_parts.append(f"<<FORM_{idx_for_form}>>")
                elif nbtype == "image":
                    idx_for_img = len(cur._images)
                    cur._images.append({
                        # âœ… ë‹¤ì–‘í•œ í‚¤ë¥¼ ëª¨ë‘ ì»¤ë²„
                        "file_name": nb.get("file_name") or nb.get("image_path") or nb.get("img_path") or nb.get("src") or "",
                        "bbox": nb.get("bbox") or [],
                        "page_idx": nb.get("page_idx"),
                        "title": _guess_image_title(blocks, j),
                    })
                    big_parts.append(f"\n<<IMG_{idx_for_img}>>\n")
                elif (nbtype == "table"
                      or nb.get("table_body")
                      or (nb.get("html") and "<table" in str(nb.get("html")).lower())
                      or (nb.get("text") and "<table" in str(nb.get("text")).lower())):
                    html_src = nb.get("table_body") or nb.get("html") or nb.get("text") or ""
                    if html_src:
                        start_pos = 0
                        while True:
                            m_tbl = RE_HTML_TABLE.search(html_src, start_pos)
                            if not m_tbl: break
                            idx_for_tbl = len(cur._tables)
                            caption = " ".join(nb.get("table_caption") or [])
                            title = clean_text(caption or nb.get("title") or nb.get("caption") or "")
                            cur._tables.append({
                                "html": sanitize_table_html(m_tbl.group(0)),
                                # âœ… í‘œ ì´ë¯¸ì§€ë„ ë‹¤ì–‘í•œ í‚¤ ì§€ì›
                                "file_name": nb.get("file_name") or nb.get("image_path") or nb.get("table_img_path") or nb.get("img_path") or "",
                                "bbox": nb.get("bbox") or [],
                                "page_idx": nb.get("page_idx"),
                                "title": title,
                            })
                            big_parts.append(f"\n<<TBL_{idx_for_tbl}>>\n")
                            start_pos = m_tbl.end()
                j += 1

            big = "\n".join(big_parts).strip()
            choices, prefix = slice_choices_by_markers_tailonly(big)
            if choices:
                if prefix:
                    to_body, to_view = route_prefix_generically(prefix)
                    if to_body: cur.body = (cur.body + ("\n" if cur.body else "") + to_body).strip()
                    if to_view: cur.view = (cur.view + ("\n" if cur.view else "") + to_view).strip()
                for lab, body in choices:
                    cur.choices[str(lab)] = body  # ë¼ë²¨ì€ ì›í˜•ìˆ«ì ê·¸ëŒ€ë¡œ ì €ì¥
                cur._chunks.append(big)
                i = j; continue
            else:
                if prefix:
                    to_body, to_view = route_prefix_generically(prefix)
                    if to_body: cur.body = (cur.body + ("\n" if cur.body else "") + to_body).strip()
                    if to_view: cur.view = (cur.view + ("\n" if cur.view else "") + to_view).strip()
                if big:
                    big2 = re.sub(r"[ \t]+\n", "\n", big)
                    big2 = re.sub(r"\n{3,}", "\n\n", big2).strip()
                    cur.body += ("\n" if cur.body else "") + big2
                i = j; continue
        i += 1

    push()
    return res

# =============================================================================
# 8) íŒŒì¼/ì •ë‹µ ë¡œë”© & ë©”íƒ€ íŒŒì‹±
# =============================================================================

def load_json_or_jsonl(path: str):
    if path.lower().endswith(".jsonl"):
        items = []
        # BOM ì•ˆì „
        with open(path, "r", encoding="utf-8-sig") as f:
            for line in f:
                line = line.strip()
                if not line: continue
                items.append(json.loads(line))
        return items
    else:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)

def _strip_known_suffixes(base: str) -> str:
    return re.sub(r"(?:_content_list|_layout|_middle)$", "", base, flags=re.I)

def _parse_meta_from_filename(path_like: str) -> Dict[str, str]:
    name = os.path.basename(path_like)
    name = os.path.splitext(name)[0]
    name = _strip_known_suffixes(name)
    parts = name.split("-")
    meta = {"data_id": "", "year": "", "exam": "", "subject": "", "type": "", "data_title": ""}

    if len(parts) >= 6 and parts[-1].startswith("ë¬¸ì œ"):
        if re.fullmatch(r"\d{4}", parts[0]): meta["data_id"] = parts[0]
        if re.fullmatch(r"\d{4}", parts[1]): meta["year"] = parts[1]
        meta["type"] = parts[-2]
        meta["subject"] = parts[-3]
        meta["exam"] = "-".join(parts[2:-3]).strip()
    else:
        m = re.match(r"(?P<id>\d{4}).*?(?P<year>\d{4}).*?-ë¬¸ì œ$", name)
        meta["data_id"] = (m and m.group("id")) or (re.match(r"\d{4}", name).group(0) if re.match(r"\d{4}", name) else "")
        meta["year"] = (m and m.group("year")) or ""
        if "-ë¬¸ì œ" in name:
            head = name[: name.rfind("-ë¬¸ì œ")]
            segs = head.split("-")
            if len(segs) >= 4:
                meta["type"] = segs[-1]
                meta["subject"] = segs[-2]
                meta["exam"] = "-".join(segs[2:-2]).strip()

    title_parts = [p for p in [meta["year"], meta["exam"], meta["subject"]] if p]
    meta["data_title"] = "-".join(title_parts)
    return meta

_SUBJECT_CATEGORY_MAP = {"êµìœ¡": ("ì‹œí—˜",)}
_FLAT_SUB_MAIN = sorted(
    [(sub, main) for main, subs in _SUBJECT_CATEGORY_MAP.items() for sub in subs if sub],
    key=lambda x: len(x[0]), reverse=True,
)

def _norm(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = s.replace("ì˜ì—­", "")
    s = re.sub(r"\s+", "", s)
    return s.lower()

def _guess_category(subject: str) -> Tuple[str, str]:
    if not subject: return ("êµìœ¡", "ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜")
    s = _norm(subject)
    for sub, main in _FLAT_SUB_MAIN:
        if _norm(sub) in s: return (main, sub)
    for main in _SUBJECT_CATEGORY_MAP.keys():
        if _norm(main) in s: return (main, "")
    return ("êµìœ¡", "ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜")

def load_answer_bundle(path: str):
    """
    ì •ë‹µ/í•´ì„¤ JSON(L) ë¡œë“œ:
      - ans_map: {ë¬¸í•­ë²ˆí˜¸: ì •ë‹µ(ê°’/ë¦¬ìŠ¤íŠ¸/ì›í˜•ìˆ«ì í¬í•¨ ê°€ëŠ¥)}
      - exp_map: {ë¬¸í•­ë²ˆí˜¸: í•´ì„¤(ë¬¸ìì—´)}
      - meta_top: {"ê¸°ì¶œì—°ë„","ì‹œí—˜ëª…","ì˜ì—­","ê³¼ëª©","ì‹œí—˜ìœ í˜•","ì„¸ë¶€ê³¼ëª©","source_url"}
      - perq_map: {ë¬¸í•­ë²ˆí˜¸: {"ë‚œì´ë„","ë°°ì ","ì •ë‹µë¥ ","ë¬¸ì œìœ í˜•"}}
    """
    def _k(s):  # ë©”íƒ€ í‚¤ ì •ê·œí™”: ê³µë°± ì œê±°
        return (s or "").replace(" ", "")

    ans_map: Dict[str, Any] = {}
    exp_map: Dict[str, str] = {}
    meta_top: Dict[str, Any] = {}
    perq_map: Dict[str, Dict[str, Any]] = {}

    if not path or not os.path.exists(path):
        return ans_map, exp_map, meta_top, perq_map

    def _ingest_obj(obj: Dict[str, Any]):
        # ===== ìƒë‹¨ ë©”íƒ€(ìˆìœ¼ë©´ ê°±ì‹ ) =====
        for k in ["ê¸°ì¶œì—°ë„", "ê¸°ì¶œ ì—°ë„", "ì‹œí—˜ëª…", "ì˜ì—­", "ê³¼ëª©", "ì‹œí—˜ìœ í˜•", "ì„¸ë¶€ê³¼ëª©"]:
            if k in obj and obj[k] not in (None, ""):
                meta_top[_k(k)] = obj[k]
        # source_url (ìµœì´ˆ 1íšŒë§Œ)
        if "source_url" in obj:
            val = obj["source_url"]
            if isinstance(val, str) and val.strip() and not meta_top.get("source_url"):
                meta_top["source_url"] = val.strip()

        # ===== ì •ë‹µ =====
        raw_ans = obj.get("ë¬¸ì œë²ˆí˜¸_ì •ë‹µ") or obj.get("ë¬¸ì œë²ˆí˜¸-ì •ë‹µ") or obj.get("ë¬¸ì œë²ˆí˜¸:ì •ë‹µ")
        if isinstance(raw_ans, dict):
            for qk, v in raw_ans.items():
                sk = str(qk)
                if isinstance(v, dict):
                    if "ì •ë‹µ" in v:
                        ans_map[sk] = v.get("ì •ë‹µ")
                    sub = {}
                    for kk in ["ë‚œì´ë„", "ë°°ì ", "ì •ë‹µë¥ ", "ë¬¸ì œìœ í˜•"]:
                        if kk in v and v[kk] not in (None, ""):
                            sub[kk] = v[kk]
                    if sub:
                        perq_map.setdefault(sk, {}).update(sub)
                else:
                    ans_map[sk] = v
        elif isinstance(raw_ans, list):
            for item in raw_ans:
                if isinstance(item, dict):
                    for qk, v in item.items():
                        sk = str(qk)
                        if isinstance(v, dict):
                            if "ì •ë‹µ" in v:
                                ans_map[sk] = v.get("ì •ë‹µ")
                            sub = {}
                            for kk in ["ë‚œì´ë„", "ë°°ì ", "ì •ë‹µë¥ ", "ë¬¸ì œìœ í˜•"]:
                                if kk in v and v[kk] not in (None, ""):
                                    sub[kk] = v[kk]
                            if sub:
                                perq_map.setdefault(sk, {}).update(sub)
                        else:
                            ans_map[sk] = v

        # ===== í•´ì„¤ =====
        raw_exp = obj.get("ë¬¸ì œë²ˆí˜¸_í•´ì„¤") or obj.get("ë¬¸ì œë²ˆí˜¸-í•´ì„¤") or obj.get("ë¬¸ì œë²ˆí˜¸:í•´ì„¤")
        if isinstance(raw_exp, dict):
            for k, v in raw_exp.items():
                if v is not None and str(v).strip():
                    exp_map[str(k)] = str(v)
        elif isinstance(raw_exp, list):
            for item in raw_exp:
                if isinstance(item, dict):
                    for k, v in item.items():
                        if v is not None and str(v).strip():
                            exp_map[str(k)] = str(v)

    # ---- íŒŒì¼ í˜•ì‹ ë¶„ê¸° (.jsonl vs .json) ----
    lower = path.lower()
    if lower.endswith(".jsonl"):
        with open(path, "r", encoding="utf-8-sig") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception:
                    continue
                if isinstance(obj, dict):
                    _ingest_obj(obj)
    else:
        # .json (dict ë˜ëŠ” list ê°€ì •)
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception:
            return ans_map, exp_map, meta_top, perq_map

        if isinstance(data, dict):
            _ingest_obj(data)
        elif isinstance(data, list):
            for obj in data:
                if isinstance(obj, dict):
                    _ingest_obj(obj)

    return ans_map, exp_map, meta_top, perq_map

def collect_answer_bundles_auto(dir_hint: str, layout_dir: str) -> Dict[str, Dict[str, Any]]:
    """
    ë§¥(NFD)/ìœˆë„ìš°(NFC) ëª¨ë‘ì—ì„œ ì •ë‹µ íŒŒì¼(*-ì •ë‹µ.jsonl / *ì •ë‹µ*.jsonl)ì„
    ê²¬ê³ í•˜ê²Œ ì°¾ì•„ STEMâ†’ë§µí•‘ìœ¼ë¡œ ë°˜í™˜.
    - dir_hintê°€ ìœ íš¨í•˜ë©´ ê·¸ ê²½ë¡œë¶€í„° ì¬ê·€ íƒìƒ‰
    - ì•„ë‹ˆë©´ LAYOUT_DIRì˜ ìƒìœ„(í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ì •)ë¶€í„° ì¬ê·€ íƒìƒ‰
    """
    mapping: Dict[str, Dict[str, Any]] = {}

    roots: List[str] = []
    if dir_hint and os.path.isdir(_abs_norm(dir_hint)):
        roots.append(dir_hint)

    # LAYOUT_DIR ê¸°ì¤€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ í›„ë³´ë“¤
    ld = _abs_norm(layout_dir)
    ld_parent = os.path.dirname(ld)
    ld_grand = os.path.dirname(ld_parent)
    for r in [ld_parent, ld_grand, os.getcwd()]:
        if r and os.path.isdir(r):
            roots.append(r)

    seen_files: List[str] = []
    for root in roots:
        for pat in ["*-ì •ë‹µ.jsonl", "*ì •ë‹µ*.jsonl"]:
            found = safe_glob(root, pat, recursive=True)
            seen_files.extend(found)

    files = sorted({f for f in seen_files if f.lower().endswith(".jsonl")})

    for ap in files:
        base = os.path.basename(ap)
        m = re.match(r"^(\d{4})", base)
        if not m:
            continue
        stem = m.group(1)
        a_map, e_map = load_answer_bundle(ap)
        prev = mapping.get(stem)
        if prev:
            if base.endswith("-ì •ë‹µ.jsonl") and not os.path.basename(prev["path"]).endswith("-ì •ë‹µ.jsonl"):
                mapping[stem] = {"ans": a_map, "exp": e_map, "path": ap}
        else:
            mapping[stem] = {"ans": a_map, "exp": e_map, "path": ap}

    print(f"ğŸ” ì •ë‹µ íŒŒì¼ íƒìƒ‰ ë£¨íŠ¸: {[ _abs_norm(r) for r in roots ]}")
    print(f"ğŸ” ë°œê²¬ ì •ë‹µ íŒŒì¼ ìˆ˜: {len(files)}")
    return mapping

# ---- (ì¶”ê°€) ANSWER_DIR ì•ˆì—ì„œë§Œ ì •ë‹µ íŒŒì¼ ì°¾ê¸° ----
def find_answers_by_stem(answer_dir: str) -> Dict[str, Dict[str, Any]]:
    """
    ANSWER_DIR ì•ˆì—ì„œë§Œ ì •ë‹µ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    ìš°ì„ ìˆœìœ„: '-ì •ë‹µ.jsonl' > '-ì •ë‹µ.json' > 'ì •ë‹µ í¬í•¨ ê¸°íƒ€'
    ë°˜í™˜: { STEM: {"ans":..., "exp":..., "meta":..., "perq":..., "path":...} }
    """
    mapping: Dict[str, Dict[str, Any]] = {}
    if not answer_dir or not os.path.isdir(answer_dir):
        return mapping

    try:
        names = os.listdir(answer_dir)
    except Exception:
        return mapping

    def _priority(name_nfk: str) -> int:
        # ë‚®ì„ìˆ˜ë¡ ë” ìš°ì„ 
        if name_nfk.endswith("-ì •ë‹µ.jsonl"):
            return 0
        if name_nfk.endswith("-ì •ë‹µ.json"):
            return 1
        if "ì •ë‹µ" in name_nfk and name_nfk.endswith(".jsonl"):
            return 2
        if "ì •ë‹µ" in name_nfk and name_nfk.endswith(".json"):
            return 3
        return 9

    for fn in names:
        norm = unicodedata.normalize("NFKC", fn)
        lower = norm.lower()
        if not (lower.endswith(".jsonl") or lower.endswith(".json")):
            continue
        if "ì •ë‹µ" not in norm:
            continue

        m = re.match(r"^(\d{4})", norm)
        if not m:
            continue
        stem = m.group(1)

        ap = os.path.join(answer_dir, fn)  # ì‹¤ì œ ì ‘ê·¼ì€ ì›ë³¸ëª…
        ans_map, exp_map, meta_top, perq_map = load_answer_bundle(ap)

        prev = mapping.get(stem)
        if (not prev) or (_priority(norm) < _priority(os.path.basename(prev["path"]))):
            mapping[stem] = {
                "ans": ans_map,
                "exp": exp_map,
                "meta": meta_top,
                "perq": perq_map,
                "path": ap
            }

    return mapping

# =============================================================================
# 9) ìì› ë¡œê·¸/ë„ìš°ë¯¸
# =============================================================================

_IMAGE_LOGS: Dict[str, Dict[str, Any]] = {}

def _bbox_dict(bbox_list):
    b = bbox_list or []
    return {"x1": b[0] if len(b) >= 1 else None,
            "y1": b[1] if len(b) >= 2 else None,
            "x2": b[2] if len(b) >= 3 else None,
            "y2": b[3] if len(b) >= 4 else None}

# =============================================================================
# 10) ì¶œë ¥(ë¬¸ìì—´/JSONL)
# =============================================================================

def _choice_order_key(k: str) -> int:
    """ì„ íƒì§€ ì •ë ¬ ê¸°ì¤€: ì›í˜•ìˆ«ìâ†’ìˆ«ìê°’, ê·¸ ì™¸ëŠ” í° ê°’ìœ¼ë¡œ ë’¤ë¡œ."""
    ks = str(k)
    num = UC2NUM.get(ks)
    if num and num.isdigit():
        return int(num)
    if ks.isdigit():
        return int(ks)
    return 9999

def _make_content_from_addinfo(ai: Dict[str, Any]) -> str:
    body = ai.get("ë¬¸ì œë³¸ë¬¸", "")
    view = ai.get("ë¬¸ì œë³´ê¸°", "") or ""
    choices = ai.get("ì„ íƒì§€") or {}
    answer_text = ai.get("ì •ë‹µ", "") or ""
    explain_text = ai.get("í•´ì„¤", "") or ""

    lines = [f"[ë¬¸ì œ]: {body}".rstrip()]
    if view:
        lines[-1] += ("\n" + view)

    if choices:
        for k in sorted(choices.keys(), key=_choice_order_key):
            v = choices[k] or ""
            lines.append(f"{k}: {v}")  # këŠ” ì›í˜•ìˆ«ì ê·¸ëŒ€ë¡œ ì¶œë ¥

    lines += ["", f"[ì •ë‹µ]: {answer_text}"]
    if explain_text:
        lines += ["", explain_text]
    return "\n".join(lines).strip()

# ===== ğŸ”¶ ì •ë‹µì„ ì›í˜•ìˆ«ì ìŠ¤íƒ€ì¼ë¡œ ë§ì¶”ê¸° ìœ„í•œ í—¬í¼ë“¤ =====

def _choice_key_num_map(choice_keys) -> Dict[str, str]:
    """
    ì„ íƒì§€ í‚¤(ì˜ˆ: 'â‘ ','â‘¡',...)ì—ì„œ ìˆ«ìë¬¸ì('1','2',...) -> ì‹¤ì œ ì‚¬ìš©ëœ ì›í˜•ìˆ«ì ë¬¸ì ë§¤í•‘ì„ ë§Œë“ ë‹¤.
    ê°™ì€ ìˆ«ìê°€ ì—¬ëŸ¬ ìŠ¤íƒ€ì¼(â‘ /â“µ ë“±)ë¡œ ì¤‘ë³µë˜ë©´ ì²« ë²ˆì§¸ ê²ƒì„ ì±„íƒ.
    """
    mp: Dict[str, str] = {}
    for k in choice_keys:
        ch = str(k)
        num = UC2NUM.get(ch)  # ì›í˜•ìˆ«ìë¼ë©´ '1','2',...
        if num and num not in mp:
            mp[num] = ch
    return mp

def _to_circled_string(val: Any, choice_keys) -> str:
    """
    ì •ë‹µ í‘œê¸°ë¥¼ ì›í˜•ìˆ«ìë¡œ ë³€í™˜.
    - ì„ íƒì§€ì— ì›í˜•ìˆ«ì ë¼ë²¨ì´ ì¡´ì¬í•˜ë©´, ê·¸ ìŠ¤íƒ€ì¼ì„ ìš°ì„  ì‚¬ìš©
    - ì´ë¯¸ ì›í˜•ìˆ«ìê°€ ë“¤ì–´ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë³´ì¡´
    - ì„ íƒì§€ê°€ ì›í˜•ìˆ«ìê°€ ì—†ë‹¤ë©´ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ìœ ì§€(ê°•ì œ ë³€í™˜ X)
    """
    s = str(val)
    # ì´ë¯¸ ì›í˜•ìˆ«ìê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ 
    if re.search(RE_CIRCLED_NUM, s):
        return s

    # ì„ íƒì§€ì—ì„œ ì‚¬ìš©ëœ ì›í˜•ìˆ«ì ìŠ¤íƒ€ì¼ì„ ìš°ì„  ì‚¬ìš©
    num_map = _choice_key_num_map(choice_keys)
    has_circled_in_choices = bool(num_map)

    if not has_circled_in_choices:
        # ì„ íƒì§€ê°€ ì›í˜•ìˆ«ìê°€ ì•„ë‹ˆë©´ ì •ë‹µë„ ì›í˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜í•˜ì§€ ì•ŠìŒ
        return s

    # ë…ë¦½ ìˆ«ì(1~2ìë¦¬)ë§Œ ì›í˜•ìœ¼ë¡œ ì¹˜í™˜ (21 ì´ìƒì€ ê·¸ëŒ€ë¡œ ë‘ )
    def repl(m: re.Match) -> str:
        num = m.group(1)
        return num_map.get(num, NUM2UC.get(num, num))

    return re.sub(r'(?<!\d)(\d{1,2})(?!\d)', repl, s)

def _size_or_default(sz: Optional[Dict[str, Any]]) -> Dict[str, Optional[int]]:
    if isinstance(sz, dict) and any(v is not None for v in sz.values()):
        # channel/height/widthë§Œ ë‚¨ê¸°ê³  ì •ë ¬
        return {
            "channel": sz.get("channel"),
            "height": sz.get("height"),
            "width":  sz.get("width"),
        }
    return {"channel": None, "height": None, "width": None}

def build_kt_jsonl(
    questions: List[Question],
    meta_src_path: str,
    out_jsonl_path: str,
    answer_map: Optional[Dict[str, Any]] = None,
    explain_map: Optional[Dict[str, str]] = None,
    img_cfg: ImageConfig = None,
    answer_meta: Optional[Dict[str, Any]] = None,     # âœ… ì¶”ê°€
    perq_detail: Optional[Dict[str, Dict[str, Any]]] = None,  # âœ… ì¶”ê°€
):
    # --- íŒŒì¼ëª…ìœ¼ë¡œ íŒŒì‹±í•œ ê¸°ë³¸ ë©”íƒ€(ë°±ì—…ìš©) ---
    meta = _parse_meta_from_filename(meta_src_path)
    data_id = meta.get("data_id", "")
    fallback_year    = meta.get("year", "")
    fallback_exam    = meta.get("exam", "")
    fallback_subject = meta.get("subject", "")
    fallback_examtype = meta.get("type", "")
    data_title = meta.get("data_title", "")
    collected_date = datetime.now().strftime("%Y.%m.%d")

    # --- ì •ë‹µ ë©”íƒ€(ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©) ---
    def _m(meta_obj, key):
        if not meta_obj: return ""
        # ê³µë°± ì œê±° í‚¤ë¡œ ì €ì¥í•´ë‘ì—ˆìŒ (ex: "ê¸°ì¶œ ì—°ë„" â†’ "ê¸°ì¶œì—°ë„")
        return meta_obj.get(key, "") or ""

    # ì •ë‹µ ë©”íƒ€ í‘œì¤€í‚¤: "ê¸°ì¶œì—°ë„","ì‹œí—˜ëª…","ì˜ì—­","ê³¼ëª©","ì‹œí—˜ìœ í˜•","ì„¸ë¶€ê³¼ëª©"
    a_year     = _m(answer_meta, "ê¸°ì¶œì—°ë„") or fallback_year
    a_exam     = _m(answer_meta, "ì‹œí—˜ëª…")   or fallback_exam
    a_area     = _m(answer_meta, "ì˜ì—­")     or ""                # íŒŒì¼ëª… íŒŒì„œì—” ì—†ë˜ ê°’
    a_subject  = _m(answer_meta, "ê³¼ëª©")     or fallback_subject
    a_type     = _m(answer_meta, "ì‹œí—˜ìœ í˜•") or ""
    a_subj2    = _m(answer_meta, "ì„¸ë¶€ê³¼ëª©") or ""

    data_title = "-".join([s for s in [a_year, a_area, a_subject] if s]) \
    or "-".join([s for s in [fallback_year, "", fallback_subject] if s])

    asset_seq = 1
    max_choice_in_file = max((len(q.choices or {}) for q in questions), default=0)
    uniform_question_type = f"{max_choice_in_file}ì§€ì„ ë‹¤" if max_choice_in_file > 0 else "ì„œìˆ í˜•"

    def _lookup(map_obj, qnum: str):
        if not map_obj: return None
        cand = [qnum, qnum.lstrip("0") or qnum]
        if qnum.isdigit(): cand.append(int(qnum))
        for c in cand:
            if c in map_obj: return map_obj[c]
        return None

    def _sorted_choice_keys(keys):
        return sorted(keys, key=_choice_order_key)

    with open(out_jsonl_path, "w", encoding="utf-8") as fw:
        for q in questions:
            body_pre = q.body or ""
            view_pre = q.view or ""
            choices_pre: Dict[str, str] = q.choices or {}

            combined_text = "\n".join(
                [body_pre, view_pre]
                + [choices_pre[k] for k in _sorted_choice_keys(choices_pre.keys())]
            )

            ph_order: List[Tuple[str, int]] = []
            seen = set()
            for m in re.finditer(r"<<(IMG|FORM|TBL)_(\d+)>>", combined_text):
                key = (m.group(1), int(m.group(2)))
                if key not in seen:
                    ph_order.append(key); seen.add(key)

            content_meta: Dict[str, Any] = {}
            ph_to_tag: Dict[Tuple[str, int], str] = {}
            qnum = str(q.number).strip()
            q_data_id = f"{data_id}_{qnum}"

            # --- í”Œë ˆì´ìŠ¤í™€ë” ë³€í™˜(ì›ë³¸ ê·¸ëŒ€ë¡œ) ---
            for kind, idx in ph_order:
                tag = f"tag_{data_id}_{asset_seq:04d}"
                ph_to_tag[(kind, idx)] = tag

                if kind == "IMG":
                    img = (q._images or [])[idx] if idx < len(q._images or []) else {}
                    bbox = img.get("bbox") or []
                    src_hint = (img.get("file_name")
                                or img.get("image_path")
                                or img.get("img_path")
                                or img.get("src")
                                or "")
                    res = classify_and_store_image(src_hint, data_id or "0000", tag=tag, kind="img", cfg=img_cfg)
                    if isinstance(res, tuple) and len(res) == 3:
                        new_path, sz, src_abs = res
                    else:
                        new_path, sz = res; src_abs = ""
                    info = {
                        "type": "image",
                        "bbox": _bbox_dict(bbox),
                        "title": f"{data_id}_{qnum}_ê·¸ë¦¼",
                        "file_name": new_path or src_hint or "",
                        "img_size": _size_or_default(sz),
                    }
                    content_meta[tag] = info

                    if new_path:
                        src_key = os.path.basename(src_abs) if src_abs else os.path.basename(new_path)
                        _IMAGE_LOGS.setdefault(data_id or "0000", {})[src_key] = {
                            "src": src_abs or "", "dst": new_path, "size": sz, "kind": "img", "tag": tag,
                        }

                elif kind == "FORM":
                    form = (q._forms or [])[idx] if idx < len(q._forms or []) else {}
                    latex_with_delims = form.get("latex", "") or ""
                    bbox = form.get("bbox") or []
                    src_hint = form.get("image_path") or form.get("img_path") or form.get("file_name") or ""

                    new_path = ""; sz = {}; src_abs = ""
                    if src_hint:
                        res = classify_and_store_image(src_hint, data_id or "0000", tag=tag, kind="form", cfg=img_cfg)
                        if isinstance(res, tuple) and len(res) == 3:
                            new_path, sz, src_abs = res
                        else:
                            new_path, sz = res; src_abs = ""

                    info = {
                        "type": "formula",
                        "bbox": _bbox_dict(bbox),
                        "text": _strip_math_delims(latex_with_delims),
                        "info": "latex",
                        "file_name": new_path or src_hint or "",
                        "img_size": _size_or_default(sz),
                    }
                    content_meta[tag] = info

                    if new_path:
                        src_key = os.path.basename(src_abs) if src_abs else os.path.basename(new_path)
                        _IMAGE_LOGS.setdefault(data_id or "0000", {})[src_key] = {
                            "src": src_abs or "", "dst": new_path, "size": sz, "kind": "form", "tag": tag,
                        }

                elif kind == "TBL":
                    tbl = (q._tables or [])[idx] if idx < len(q._tables or []) else {}
                    bbox = tbl.get("bbox") or []
                    src_hint = (tbl.get("file_name")
                                or tbl.get("image_path")
                                or tbl.get("table_img_path")
                                or tbl.get("img_path")
                                or "")
                    res = classify_and_store_image(src_hint, data_id or "0000", tag=tag, kind="tbl", cfg=img_cfg)
                    if isinstance(res, tuple) and len(res) == 3:
                        new_path, sz, src_abs = res
                    else:
                        new_path, sz = res; src_abs = ""
                    info = {
                        "type": "table",
                        "bbox": _bbox_dict(bbox),
                        "text": sanitize_table_html(tbl.get("html", "") or ""),
                        "info": "html",
                        "file_name": new_path or src_hint or "",
                        "img_size": _size_or_default(sz),
                    }
                    content_meta[tag] = info

                    if new_path:
                        src_key = os.path.basename(src_abs) if src_abs else os.path.basename(new_path)
                        _IMAGE_LOGS.setdefault(data_id or "0000", {})[src_key] = {
                            "src": src_abs or "", "dst": new_path, "size": sz, "kind": "tbl", "tag": tag,
                        }

                asset_seq += 1

            def replace_ph(txt: str) -> str:
                if not txt: return txt
                def repl(m: re.Match) -> str:
                    k = (m.group(1), int(m.group(2)))
                    tag = ph_to_tag.get(k, "")
                    return f"<{tag}>" if tag else ""
                return re.sub(r"<<(IMG|FORM|TBL)_(\d+)>>", repl, txt)

            replaced_body = replace_ph(body_pre)
            replaced_view = replace_ph(view_pre)
            replaced_choices = {str(k): replace_ph(v) for k, v in choices_pre.items()}
            choices_for_addinfo = {k: clean_text(v or "") for k, v in replaced_choices.items()}

            dtype_set = set(["text"])
            for v in content_meta.values():
                t = v.get("type")
                if t in ("image", "formula", "table"): dtype_set.add(t)
            data_types = sorted(dtype_set)

            # ===== ì •ë‹µ & í•´ì„¤ =====
            ans_val = _lookup(answer_map or {}, qnum)

            def _ans_text(v, choice_keys) -> str:
                if v is None:
                    return ""
                if isinstance(v, dict):
                    inner = v.get("ì •ë‹µ", v)
                    if isinstance(inner, (list, tuple)):
                        return ",".join(_to_circled_string(x, choice_keys) for x in inner)
                    return _to_circled_string(inner, choice_keys)
                if isinstance(v, (list, tuple)):
                    return ",".join(_to_circled_string(x, choice_keys) for x in v)
                return _to_circled_string(v, choice_keys)

            answer_text = _ans_text(ans_val, replaced_choices.keys())

            explain_text = ""
            ev = _lookup(explain_map or {}, qnum)
            if ev is not None:
                explain_text = str(ev).strip()

            # ===== ë¬¸í•­ë³„ ì„¸ë¶€(ë‚œì´ë„/ë°°ì /ì •ë‹µë¥ /ë¬¸ì œìœ í˜•) =====
            pdet = (perq_detail or {}).get(qnum, {}) if perq_detail else {}
            diff  = pdet.get("ë‚œì´ë„", "")
            score = pdet.get("ë°°ì ", "")
            rate  = pdet.get("ì •ë‹µë¥ ", "")
            qtype = uniform_question_type

            # ===== add_info êµ¬ì„± =====
            ai = {
                "ë¬¸ì œë²ˆí˜¸": qnum,
                # â–¼ ìš”êµ¬ì‚¬í•­: íŒŒì¼ëª… íŒŒì‹±ê°’ ëŒ€ì‹  ì •ë‹µ JSONL ë©”íƒ€ ìš°ì„ 
                "ê¸°ì¶œì—°ë„": a_year,
                "ì‹œí—˜ëª…": a_exam,
                "ì˜ì—­": a_area,
                "ê³¼ëª©": a_subject,
                **({"ì‹œí—˜ìœ í˜•": a_type} if a_type else {}),
                **({"ì„¸ë¶€ê³¼ëª©": a_subj2} if a_subj2 else {}),
                # ë³¸ë¬¸/ë³´ê¸°/ì„ íƒì§€/ì •ë‹µ/í•´ì„¤
                **({"ë¬¸ì œìœ í˜•": qtype} if qtype != "" else {}),
                "ë¬¸ì œë³¸ë¬¸": replaced_body,
                **({"ë¬¸ì œë³´ê¸°": replaced_view} if replaced_view else {}),
                "ì„ íƒì§€": choices_for_addinfo,  # (ë¼ë²¨ì€ ì›í˜•ìˆ«ì ìœ ì§€)
                "ì •ë‹µ": answer_text,
                **({"í•´ì„¤": explain_text} if explain_text else {}),
                # â–¼ ë¬¸í•­ë³„ ì„¸ë¶€ í•„ë“œ(ì •ë‹µ JSONLì—ì„œ)
                **({"ë‚œì´ë„": diff} if diff != "" else {}),
                **({"ë°°ì ": score} if score != "" else {}),
                **({"ì •ë‹µë¥ ": rate} if rate != "" else {}),
            }

            content = _make_content_from_addinfo(ai)

            rec = {
                "data_id": q_data_id,
                "data_file": os.path.basename(out_jsonl_path),
                "data_title": data_title,
            }

            if answer_meta and "source_url" in answer_meta and answer_meta["source_url"]:
                rec["source_url"] = answer_meta["source_url"]

            rec.update({
                "category_main": _guess_category(a_subject)[0],  # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ìœ ì¶” ë¡œì§ ì¬ì‚¬ìš©
                **({"category_sub": _guess_category(a_subject)[1]} if _guess_category(a_subject)[1] else {}),
                "data_type": data_types,
                "collected_date": collected_date,
                "content": content,
                **({"content_meta": content_meta} if content_meta else {}),
                "add_info": ai,
            })    
            
            fw.write(json.dumps(rec, ensure_ascii=False) + "\n")

# =============================================================================
# 11) ë©”ì¸ â€” LAYOUT_DIR ë‚´ì˜ ëª¨ë“  .json ì²˜ë¦¬
# =============================================================================

def main():
    ensure_dir(FORMAT_DIR)
    ensure_dir(IMAGES_IMG_DIR)
    ensure_dir(IMAGES_TBL_DIR)
    ensure_dir(IMAGES_FORM_DIR)   # âœ… ìˆ˜ì‹ í´ë” ìƒì„±
    ensure_dir(IMAGES_INDEX_DIR)

    IMG_CFG = ImageConfig(
        src_root=IMAGES_SRC_DIR,
        dst_img_root=IMAGES_IMG_DIR,
        dst_tbl_root=IMAGES_TBL_DIR,
        dst_form_root=IMAGES_FORM_DIR,  # âœ… ì¶”ê°€
        move=IMAGE_MOVE,
        overwrite=IMAGE_OVERWRITE,
    )

    # âœ… ì •ë‹µ íŒŒì¼: ANSWER_DIR ì•ˆì—ì„œë§Œ íƒìƒ‰
    answers_by_stem = find_answers_by_stem(ANSWER_DIR)

    layout_paths = sorted(glob.glob(os.path.join(_abs_norm(LAYOUT_DIR), "*.json")))
    if not layout_paths:
        print(f"âš ï¸ ì…ë ¥(.json) íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {LAYOUT_DIR}")

    total_q = 0
    total_no_choice = 0
    total_choice_parse_error = 0

    for LAYOUT_JSON in layout_paths:
        base = os.path.basename(LAYOUT_JSON)
        m = re.match(r"^(\d{4})", base)
        if not m:
            print(f"â­ï¸ ìŠ¤í‚µ(ì• 4ìë¦¬ ìˆ«ì ì—†ìŒ): {base}")
            continue

        STEM = m.group(1)
        format_name = os.path.splitext(base)[0].removesuffix("_merge")
        FORMAT_JSONL = os.path.join(FORMAT_DIR, f"{format_name}.jsonl")

        a_entry = answers_by_stem.get(STEM, {})
        answer_map = a_entry.get("ans") or {}
        explain_map = a_entry.get("exp") or {}
        answer_meta = a_entry.get("meta") or {}
        perq_detail = a_entry.get("perq") or {} 
        ans_path = a_entry.get("path")

        try:
            raw = load_json_or_jsonl(LAYOUT_JSON)
            data = extract(raw)

            max_choice_in_file = max((len(q.choices or {}) for q in data), default=0)
            choice_parse_errors = []
            if max_choice_in_file > 0:
                for q in data:
                    n_choices = len(q.choices or {})
                    if n_choices < max_choice_in_file:
                        choice_parse_errors.append(q.number)

            total_q += len(data)
            total_choice_parse_error += len(choice_parse_errors)

            build_kt_jsonl(
                data, LAYOUT_JSON, FORMAT_JSONL,
                answer_map=answer_map,
                explain_map=explain_map,
                img_cfg=IMG_CFG,
                answer_meta=answer_meta,
                perq_detail=perq_detail, 
            )

            if STEM in _IMAGE_LOGS:
                idx_path = os.path.join(IMAGES_INDEX_DIR, f"{STEM}.json")
                ensure_dir(os.path.dirname(idx_path))
                with open(idx_path, "w", encoding="utf-8") as f:
                    json.dump(_IMAGE_LOGS[STEM], f, ensure_ascii=False, indent=2)

            no_choice = [q.number for q in data if not q.choices]
            total_no_choice += len(no_choice)

            print(f"\nğŸ“„ ì²˜ë¦¬ ëŒ€ìƒ: {base}")
            print(f"   STEM: {STEM}")
            print(f"   âœ… ì…ë ¥: {LAYOUT_JSON}")
            if ans_path:
                print(f"   âœ… ì ìš©(ì •ë‹µ/í•´ì„¤): {ans_path} | ì •ë‹µ {len(answer_map)}ê°œ, í•´ì„¤ {len(explain_map)}ê°œ")
            else:
                print(f"   âš ï¸ ì ìš©í•  ì •ë‹µ íŒŒì¼ ì—†ìŒ (STEM={STEM})")
            print(f"   âœ… ì €ì¥(KT): {FORMAT_JSONL}")
            if max_choice_in_file > 0:
                print(f"   âœ… ê¸°ëŒ€ ë³´ê¸° ìˆ˜: {max_choice_in_file}ì§€ì„ ë‹¤")
                print(f"   âš ï¸ ì„ íƒì§€ íŒŒì‹± ì˜¤ë¥˜: {len(choice_parse_errors)} -> {choice_parse_errors}")
            print(f"   âœ… ë¬¸í•­ìˆ˜: {len(data)} / ì„ íƒì§€ ì—†ëŠ” ë¬¸í•­: {len(no_choice)} -> {no_choice}")
            print(f"   ğŸ“¦ ì´ë¯¸ì§€ ì¸ë±ìŠ¤: {os.path.join(IMAGES_INDEX_DIR, f'{STEM}.json')}")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {base} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    print(f"\nğŸ¯ ì´ ì²˜ë¦¬ íŒŒì¼: {len(layout_paths)} / ì´ ë¬¸í•­ìˆ˜: {total_q} / ì„ íƒì§€ ì—†ëŠ” ë¬¸í•­ ìˆ˜: {total_no_choice}")

if __name__ == "__main__":
    main()
